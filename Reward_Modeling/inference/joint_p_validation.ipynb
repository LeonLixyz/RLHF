{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/al4263/.conda/envs/rlhf_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-24 16:11:38,965] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "# import parent directory \n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"/user/al4263/rlhf/Reward_Modeling\")\n",
    "import utils\n",
    "import models\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models import RewardENN\n",
    "from data.data_loader import pairwise_data_tokenized, PairwiseDyadicAugmentedTokenizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/shared/share_mala/leon/llama-3b-sft-hh\"\n",
    "from models.reward_enn import RewardENN, RewardENNConfig\n",
    "from models.vanilla_reward import VanillaReward, VanillaRewardConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "config = RewardENNConfig(\n",
    "            backbone_model_name_or_path=output_dir,\n",
    "            ref_size=10,\n",
    "            enn_hidden_size=64,\n",
    "            enn_output_size=1,\n",
    "            enn_gain=1.0,\n",
    "            lmbda=1.0,\n",
    "            )\n",
    "\n",
    "model = RewardENN.from_pretrained(\n",
    "    \"/shared/share_mala/leon/reward-enn/anthropic_hh/-ref_size10-enn_dim64-num_ref_train10-lr1e-05-weight_decay0.01-enn_lr0.001-enn_decay0.1-reward_lr0.0003-reward_decay0.1-gc1-train_batch_size4\",\n",
    "    flash_attn=False,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer:LlamaTokenizerFast(name_or_path='/shared/share_mala/leon/llama-3b-sft-hh', vocab_size=32000, model_max_length=512, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        output_dir,\n",
    "        padding_side=\"left\",)\n",
    "print(\"tokenizer:\" + str(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "data_dir = '/user/al4263/rlhf/Reward_Modeling/data/dataset/anthropic_hh/unaug_joint_eval.json'\n",
    "with open(data_dir) as f:\n",
    "     annotated = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    \"prompt_noinputs\": \"{input}\",\n",
    "    \"prompt_inputs\": \"{input}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_dataset = PairwiseDyadicAugmentedTokenizedData(annotated, tokenizer, 512, prompts)\n",
    "dataloader = torch.utils.data.DataLoader(joint_dataset, batch_size= 1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [04:50<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_joint_likelihood: tensor(-1256., dtype=torch.bfloat16)\n",
      "joint_log_likelihood: tensor(-1416., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "joint_log_list = []\n",
    "log_joint_list = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        p_1_ids, p_2_ids, p_1_att, p_2_att, labels = batch\n",
    "        p_1_ids = p_1_ids.squeeze()\n",
    "        p_2_ids = p_2_ids.squeeze()\n",
    "        p_1_att = p_1_att.squeeze()\n",
    "        p_2_att = p_2_att.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "        p_1_ids = p_1_ids.to(device)\n",
    "        p_2_ids = p_2_ids.to(device)\n",
    "        p_1_att = p_1_att.to(device)\n",
    "        p_2_att = p_2_att.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        z_samples = torch.randn(10, 10).to(device)\n",
    "        z_samples = z_samples.to(torch.bfloat16)\n",
    "\n",
    "        reward_list_1 = model(p_1_ids, attention_mask=p_1_att, z_samples=z_samples, return_full_z=True).reward_list \n",
    "        reward_list_2 = model(p_2_ids, attention_mask=p_2_att, z_samples=z_samples, return_full_z=True).reward_list \n",
    "\n",
    "\n",
    "        r_win = torch.where(labels.unsqueeze(-1) == 1, reward_list_1, reward_list_2)\n",
    "        r_lose = torch.where(labels.unsqueeze(-1) == 2, reward_list_1, reward_list_2)\n",
    "        stack_rewards = torch.stack((r_win, r_lose), dim=2)\n",
    "        #print(\"stack_rewards\", stack_rewards, stack_rewards.shape)\n",
    "        # joint log likelihood\n",
    "        log_softmax_values = torch.nn.functional.log_softmax(stack_rewards, dim=2)[:,:,0]\n",
    "        # averaging over the z samples, if vanilla then dimension is 1 so no effect\n",
    "        log_softmax_values = torch.mean(log_softmax_values, dim=1)\n",
    "        # summing all dyadic samples\n",
    "        joint_log_likelihood = torch.sum(log_softmax_values, dim=0)\n",
    "        joint_log_list.append(joint_log_likelihood)\n",
    "\n",
    "        # log joint likelihood for evaluation\n",
    "        softmax_values = torch.nn.functional.softmax(stack_rewards, dim=2)[:,:,0]\n",
    "        #print(\"softmax_values\", softmax_values, softmax_values.shape)\n",
    "        product_softmax_values = torch.prod(softmax_values, dim=0)\n",
    "        #print(\"product_softmax_values\", product_softmax_values, product_softmax_values.shape)\n",
    "        # Averaging over the z samples, if vanilla then dimension is 1 so no effect\n",
    "        avg_softmax_values = torch.mean(product_softmax_values)\n",
    "        #print(\"avg_softmax_values\", avg_softmax_values, avg_softmax_values.shape)\n",
    "        # log joint likelihood\n",
    "        log_joint_likelihood = torch.log(avg_softmax_values)\n",
    "        log_joint_list.append(log_joint_likelihood)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    log_joint_likelihood = torch.tensor(log_joint_list).sum()\n",
    "    joint_log_likelihood = torch.tensor(joint_log_list).sum()\n",
    "\n",
    "    print(\"log_joint_likelihood: \" + str(log_joint_likelihood))\n",
    "    print(\"joint_log_likelihood: \" + str(joint_log_likelihood))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
